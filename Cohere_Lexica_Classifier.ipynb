{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep in mind a prompt dump is available here, which I believe is just one per line\n",
    "#https://github.com/Jeremy-Fuller/Prompts/blob/main/prompts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this as example\n",
    "# https://lablab.ai/t/cohere-text-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cohere\n",
    "from cohere.classify import Example\n",
    "\n",
    "COHERE_KEY = open(\"cohere-key.txt\", \"r\").readlines(0)[0][:-1]\n",
    "\n",
    "co = cohere.Client(f'{COHERE_KEY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lexica_prompts_df.csv\")\n",
    "df.head()\n",
    "# should I remove the keyword from the prompt??\n",
    "\n",
    "for k in df.keyword.unique():\n",
    "    df[\"prompts_without_keywords\"] = df.prompt.apply(lambda x: x.replace(k, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      detailed portrait Neon Operator Girl, cyberpun...\n",
       "1      detailed portrait of cyberpunk computer scient...\n",
       "2      cyberpunk huntress. this pastel painting by th...\n",
       "3      a beautiful portrait painting of a cyberpunk g...\n",
       "4      cyberpunk princess. this watercolor painting b...\n",
       "                             ...                        \n",
       "245    full body  photograph of kate upton as a steam...\n",
       "246    steampunk helmet fantasy art mask robot ninja ...\n",
       "247    machine, steampunk, edo style, lilia alvarado,...\n",
       "248    full body photograph of kate upton as a steamp...\n",
       "249    an extremely complex and advanced steampunk ce...\n",
       "Name: prompt, Length: 250, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = [Example(p, l) for p, l in zip(df.prompts_without_keywords, df.keyword)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = co.classify(inputs = [\"a futuristic robot with a massive sombrero\", \n",
    "                                 \"a landscape shot of icy mountains in the Andes\",\n",
    "                                \"A cozy cabin with lots of mushrooms and soft things\",\n",
    "                                \"A painting of a bunch of greenery like trees and bushes\",\n",
    "                                \"A real life dog, with realistic fur\"],\n",
    "                      examples = EXAMPLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input was a futuristic robot with a massive sombrero and the prediction was steampunk\n",
      "The input was a landscape shot of icy mountains in the Andes and the prediction was water colors\n",
      "The input was A cozy cabin with lots of mushrooms and soft things and the prediction was cottage core\n",
      "The input was A painting of a bunch of greenery like trees and bushes and the prediction was water colors\n",
      "The input was A real life dog, with realistic fur and the prediction was photorealistic\n"
     ]
    }
   ],
   "source": [
    "for x in response.classifications:\n",
    "    print(f'The input was {x.input} and the prediction was {x.prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cohere.Confidence {\n",
       " \tlabel: cyberpunk\n",
       " \tconfidence: 0.041237958\n",
       " },\n",
       " cohere.Confidence {\n",
       " \tlabel: photorealistic\n",
       " \tconfidence: 0.00043258982\n",
       " },\n",
       " cohere.Confidence {\n",
       " \tlabel: cottage core\n",
       " \tconfidence: 3.906211e-05\n",
       " },\n",
       " cohere.Confidence {\n",
       " \tlabel: water colors\n",
       " \tconfidence: 5.0685307e-05\n",
       " },\n",
       " cohere.Confidence {\n",
       " \tlabel: steampunk\n",
       " \tconfidence: 0.95823973\n",
       " }]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.classifications[0].confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohere.Confidence {\n",
       "\tlabel: cyberpunk\n",
       "\tconfidence: 0.041237958\n",
       "}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.classifications[0].confidence[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating variations of the existing entries in Lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_text = open(\"prompts.txt\", \"r\").readlines()\n",
    "prompts_text = [x.replace(\"\\n\", \" \\n--SEPARATOR--\\n \") for x in prompts_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_text = \" \".join(prompts_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lexica_dump_prompts.txt', 'w') as f:\n",
    "    f.write(prompts_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_prompt = \"This is a prompt that is used to generate images in the style of cyberpunk art, and is followed by a sentence rephrasing this prompt:\\n\"\n",
    "output_prompt= \" \\nThe above cyberpunk prompt can also be phrased as:\\n \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'detailed portrait Neon Operator Girl, cyberpunk futuristic neon, reflective puffy coat, decorated with traditional Japanese ornaments by Ismail inceoglu dragan bibin hans thoma greg rutkowski Alexandros Pyromallis Nekro Rene Maritte Illustrated, Perfect face, fine details, realistic shaded, fine-face, pretty face'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cohere.Generations {\n",
       "\tgenerations: [cohere.Generation {\n",
       "\ttext:  \n",
       "\n",
       "Take your character, portrait them and make a detailed portrait of them, so that they appear\n",
       "\tlikelihood: None\n",
       "\ttoken_likelihoods: None\n",
       "}]\n",
       "\treturn_likelihoods: NONE\n",
       "}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#approach one, task description and general setting\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "co.generate(prompt = initial_prompt  + df.prompt[0] + output_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach two, provide examples of the current situation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# just ask for keywords\n",
    "\n",
    "generated_things = co.generate(prompt = \"\"\"This is a list of possible cyberpunk keywords to add to a prompt for an image generation model.\n",
    "The keywords related to the cyberpunk art style:\\n\n",
    "1. futuristic city\\n\n",
    "2. cybernetic enhancements on body\\n\n",
    "3. neon lights\\n\"\"\", max_tokens = 50, num_generations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[cohere.Generation {\n",
       " \ttext: \n",
       " \n",
       " 4. use of jagged edges\n",
       " \n",
       " 5. technology with an artificial feel\n",
       " \n",
       " 6. the city is a technological artifact\n",
       " \n",
       " 7. wires\n",
       " \n",
       " 8. cities with light pollution\n",
       " \n",
       " 9. cyberpunk literature and film\n",
       " \tlikelihood: None\n",
       " \ttoken_likelihoods: None\n",
       " },\n",
       " cohere.Generation {\n",
       " \ttext: \n",
       " \n",
       " 4. high-tech\n",
       " \n",
       " 5. war or conflict\n",
       " \n",
       " 6. prosthetic arms and legs\n",
       " \n",
       " 7. weapons\n",
       " \n",
       " 8. body modification\n",
       " \n",
       " 9. biomechanical or organic body\n",
       " \n",
       " 10. force field\n",
       " \n",
       " \tlikelihood: None\n",
       " \ttoken_likelihoods: None\n",
       " },\n",
       " cohere.Generation {\n",
       " \ttext: \n",
       " \n",
       " 4. urban decay\n",
       " \n",
       " 5. future world (predictions)\n",
       " \n",
       " 6. vat-grown people\n",
       " \n",
       " 7. megacorporations\n",
       " \n",
       " 8. bioengineering\n",
       " \n",
       " 9. non-humans (cyborg\n",
       " \tlikelihood: None\n",
       " \ttoken_likelihoods: None\n",
       " },\n",
       " cohere.Generation {\n",
       " \ttext: \n",
       " \n",
       " 4. urban decay\n",
       " \n",
       " 5. future world (predictions)\n",
       " \n",
       " 6. vat-grown people\n",
       " \n",
       " 7. megacorporations\n",
       " \n",
       " 8. bioengineering\n",
       " \n",
       " 9. non-humans (cyborg\n",
       " \tlikelihood: None\n",
       " \ttoken_likelihoods: None\n",
       " },\n",
       " cohere.Generation {\n",
       " \ttext: \n",
       " \n",
       " 4. use of jagged edges\n",
       " \n",
       " 5. technology with an artificial feel\n",
       " \n",
       " 6. the city is a technological artifact\n",
       " \n",
       " 7. wires\n",
       " \n",
       " 8. cities with light pollution\n",
       " \n",
       " 9. cyberpunk literature and film\n",
       " \tlikelihood: None\n",
       " \ttoken_likelihoods: None\n",
       " }]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_things.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mWarning: Your text contains a trailing whitespace, which has been trimmed to ensure high quality generations.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cohere.Generations {\n",
       "\tgenerations: [cohere.Generation {\n",
       "\ttext: \n",
       "\n",
       "4. tree lined country road\n",
       "\n",
       "5. reindeer\n",
       "\n",
       "6. small wood cabin\n",
       "\n",
       "7. ice fishing shack\n",
       "\n",
       "8. sunset over the woods\n",
       "\n",
       "9. coniferous forest\n",
       "\n",
       "10.\n",
       "\tlikelihood: None\n",
       "\ttoken_likelihoods: None\n",
       "}, cohere.Generation {\n",
       "\ttext: \n",
       "\n",
       "4. wood stove\n",
       "\n",
       "5. stucco\n",
       "\n",
       "6. \"home\"\n",
       "\n",
       "7. shiplap\n",
       "\n",
       "8. farmhouse sink\n",
       "\n",
       "9. antler chandelier\n",
       "\n",
       "10. live edge\n",
       "\n",
       "\tlikelihood: None\n",
       "\ttoken_likelihoods: None\n",
       "}, cohere.Generation {\n",
       "\ttext: \n",
       "\n",
       "4. tree lined country road\n",
       "\n",
       "5. reindeer\n",
       "\n",
       "6. small wood cabin\n",
       "\n",
       "7. ice fishing shack\n",
       "\n",
       "8. sunset over the woods\n",
       "\n",
       "9. coniferous forest\n",
       "\n",
       "10.\n",
       "\tlikelihood: None\n",
       "\ttoken_likelihoods: None\n",
       "}, cohere.Generation {\n",
       "\ttext: \n",
       "\n",
       "4. wood stove\n",
       "\n",
       "5. stucco\n",
       "\n",
       "6. \"home\"\n",
       "\n",
       "7. shiplap\n",
       "\n",
       "8. farmhouse sink\n",
       "\n",
       "9. antler chandelier\n",
       "\n",
       "10. live edge\n",
       "\n",
       "\tlikelihood: None\n",
       "\ttoken_likelihoods: None\n",
       "}, cohere.Generation {\n",
       "\ttext: \n",
       "\n",
       "4. sloping lawn\n",
       "\n",
       "5. white wooden farmhouse\n",
       "\n",
       "6. oak and beech forests\n",
       "\n",
       "7. rock and moss covered mountains\n",
       "\n",
       "8. farm and farmhouse in the countryside\n",
       "\n",
       "9. nature\n",
       "\tlikelihood: None\n",
       "\ttoken_likelihoods: None\n",
       "}]\n",
       "\treturn_likelihoods: NONE\n",
       "}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "co.generate(prompt = \"\"\"This is a list of possible cottagecore keywords to add to a prompt for an image generation model.\n",
    "The keywords related to the cottagecore art style:\\n\n",
    "1. cozy cabin\\n\n",
    "2. red and white spotted mushrooms\\n\n",
    "3. bucolic landscape\\n\"\"\", max_tokens = 50, temperature = 0.85, num_generations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write some code to segment this feedback\n",
    "\n",
    "#write a wrapper to clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyberpunk_df = df[df.keyword == \"cyberpunk\"].reset_index(drop=True).prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyberpunk_df = \"\\n--SEPARATOR--\\n\".join(list(cyberpunk_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cyberpunk.txt\", \"w\") as f:\n",
    "    f.write(cyberpunk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
